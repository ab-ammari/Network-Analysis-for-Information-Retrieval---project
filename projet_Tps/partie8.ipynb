{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 8.1 : Classification supervisée\n",
    "# M2 MIASHS : projet Network Analysis for Information Retrieval\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pour le traitement du texte\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Pour les graphes\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "# Pour les modèles de classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pour les visualisations\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Pour NLTK et gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Configuration pour un meilleur affichage\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================================================\n",
    "# 1. Chargement et préparation des données\n",
    "#===========================================================================================\n",
    "\n",
    "def load_processed_data(file_path):\n",
    "    \"\"\"\n",
    "    Charge les données traitées lors des exercices précédents.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Chemin du fichier pickle contenant le DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame contenant les articles\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_pickle(file_path)\n",
    "        print(f\"Données chargées avec succès. Shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données: {e}\")\n",
    "        return None\n",
    "\n",
    "def prepare_text_column(df, text_column='combined_text'):\n",
    "    \"\"\"\n",
    "    Prépare une colonne de texte combiné (titre + résumé) si nécessaire.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame contenant les articles\n",
    "        text_column (str): Nom de la colonne à créer\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame avec la colonne de texte combiné\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Vérifier si la colonne existe déjà\n",
    "    if text_column not in df_copy.columns:\n",
    "        print(f\"Création de la colonne '{text_column}'...\")\n",
    "        # Combiner le titre et le résumé\n",
    "        df_copy[text_column] = df_copy.apply(\n",
    "            lambda row: f\"{row['title']} {row.get('abstract', '') if pd.notna(row.get('abstract', '')) else ''}\",\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def explore_class_distribution(df, class_column='class'):\n",
    "    \"\"\"\n",
    "    Explore la distribution des classes et crée une visualisation.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame contenant les articles\n",
    "        class_column (str): Nom de la colonne contenant les étiquettes de classe\n",
    "        \n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: Figure de la distribution des classes\n",
    "    \"\"\"\n",
    "    if class_column not in df.columns:\n",
    "        print(f\"Colonne de classe '{class_column}' non trouvée.\")\n",
    "        return None\n",
    "    \n",
    "    # Mapping des classes\n",
    "    class_mapping = {\n",
    "        1: \"Artificial Intelligence\",\n",
    "        2: \"Data Science\",\n",
    "        3: \"Interface\",\n",
    "        4: \"Computer Vision\",\n",
    "        5: \"Network\",\n",
    "        6: \"Theoretical CS\",\n",
    "        7: \"Specific Applications\",\n",
    "        8: \"Other\"\n",
    "    }\n",
    "    \n",
    "    # Distribution des classes\n",
    "    class_counts = df[class_column].value_counts().sort_index()\n",
    "    \n",
    "    # Création d'un DataFrame pour la visualisation\n",
    "    df_viz = pd.DataFrame({\n",
    "        'class_id': class_counts.index,\n",
    "        'count': class_counts.values,\n",
    "        'class_name': [class_mapping.get(c, f\"Class {c}\") for c in class_counts.index]\n",
    "    })\n",
    "    \n",
    "    # Création de la figure\n",
    "    fig = px.bar(\n",
    "        df_viz,\n",
    "        x='class_id',\n",
    "        y='count',\n",
    "        color='class_name',\n",
    "        labels={'class_id': 'Classe', 'count': 'Nombre d\\'articles', 'class_name': 'Domaine'},\n",
    "        title='Distribution des classes dans le corpus',\n",
    "        text='count'\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(textposition='outside')\n",
    "    fig.update_layout(height=500, width=900)\n",
    "    \n",
    "    # Afficher les statistiques\n",
    "    total = df_viz['count'].sum()\n",
    "    print(f\"Nombre total d'articles classifiés: {total}\")\n",
    "    \n",
    "    for i, row in df_viz.iterrows():\n",
    "        print(f\"Classe {row['class_id']} ({row['class_name']}): {row['count']} articles ({row['count']/total*100:.1f}%)\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "#===========================================================================================\n",
    "# 2. Extraction de features textuelles\n",
    "#===========================================================================================\n",
    "\n",
    "class TextFeatureExtractor:\n",
    "    \"\"\"Classe pour l'extraction de features textuelles.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, text_column='combined_text', class_column='class'):\n",
    "        \"\"\"\n",
    "        Initialise la classe avec le DataFrame d'articles.\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame contenant les articles\n",
    "            text_column (str): Nom de la colonne contenant le texte\n",
    "            class_column (str): Nom de la colonne contenant les étiquettes de classe\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.text_column = text_column\n",
    "        self.class_column = class_column\n",
    "        \n",
    "        # Vérification des colonnes\n",
    "        if text_column not in df.columns:\n",
    "            raise ValueError(f\"Colonne de texte '{text_column}' non trouvée dans le DataFrame.\")\n",
    "        \n",
    "        if class_column not in df.columns:\n",
    "            raise ValueError(f\"Colonne de classe '{class_column}' non trouvée dans le DataFrame.\")\n",
    "        \n",
    "        # Prétraitement\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "        \n",
    "        # Ajout de stop words spécifiques au domaine scientifique\n",
    "        scientific_stop_words = [\n",
    "            'doi', 'fig', 'figure', 'et', 'al', 'paper', 'study', 'research',\n",
    "            'method', 'results', 'analysis', 'data', 'proposed', 'approach',\n",
    "            'using', 'based', 'used', 'show', 'shown', 'table', 'section'\n",
    "        ]\n",
    "        self.stop_words.update(scientific_stop_words)\n",
    "        \n",
    "        # Attributs pour stocker les résultats\n",
    "        self.vectorizer = None\n",
    "        self.features = None\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Prétraite un texte (minuscules, retrait ponctuation, etc.)\n",
    "        \n",
    "        Args:\n",
    "            text (str): Texte à prétraiter\n",
    "            \n",
    "        Returns:\n",
    "            str: Texte prétraité\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Conversion en minuscules\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Suppression des chiffres et de la ponctuation\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        \n",
    "        # Suppression des espaces multiples\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize_and_stem(self, text):\n",
    "        \"\"\"\n",
    "        Tokenise et applique le stemming au texte.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Texte à tokeniser\n",
    "            \n",
    "        Returns:\n",
    "            list: Liste de stems\n",
    "        \"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        return [self.stemmer.stem(word) for word in words if word.lower() not in self.stop_words]\n",
    "    \n",
    "    def extract_tfidf_features(self, min_df=5, max_df=0.95, max_features=None, ngram_range=(1, 2)):\n",
    "        \"\"\"\n",
    "        Extrait les features TF-IDF du texte.\n",
    "        \n",
    "        Args:\n",
    "            min_df (int): Fréquence minimale des termes\n",
    "            max_df (float): Fréquence maximale des termes\n",
    "            max_features (int): Nombre maximum de features\n",
    "            ngram_range (tuple): Plage de n-grammes (min, max)\n",
    "            \n",
    "        Returns:\n",
    "            scipy.sparse.csr_matrix: Matrice des features TF-IDF\n",
    "        \"\"\"\n",
    "        print(\"Extraction des features TF-IDF...\")\n",
    "        \n",
    "        # Création du vectoriseur\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            preprocessor=self.preprocess_text,\n",
    "            tokenizer=self.tokenize_and_stem,\n",
    "            min_df=min_df,\n",
    "            max_df=max_df,\n",
    "            max_features=max_features,\n",
    "            ngram_range=ngram_range,\n",
    "            norm='l2',\n",
    "            use_idf=True\n",
    "        )\n",
    "        \n",
    "        # Extraction des features\n",
    "        start_time = time.time()\n",
    "        self.features = self.vectorizer.fit_transform(self.df[self.text_column])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Récupération des noms des features\n",
    "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"Extraction terminée en {end_time - start_time:.2f} secondes.\")\n",
    "        print(f\"Nombre de features: {len(self.feature_names)}\")\n",
    "        print(f\"Dimensions de la matrice: {self.features.shape}\")\n",
    "        \n",
    "        return self.features\n",
    "    \n",
    "    def extract_bow_features(self, min_df=5, max_df=0.95, max_features=None, ngram_range=(1, 1)):\n",
    "        \"\"\"\n",
    "        Extrait les features Bag-of-Words (Count) du texte.\n",
    "        \n",
    "        Args:\n",
    "            min_df (int): Fréquence minimale des termes\n",
    "            max_df (float): Fréquence maximale des termes\n",
    "            max_features (int): Nombre maximum de features\n",
    "            ngram_range (tuple): Plage de n-grammes (min, max)\n",
    "            \n",
    "        Returns:\n",
    "            scipy.sparse.csr_matrix: Matrice des features BoW\n",
    "        \"\"\"\n",
    "        print(\"Extraction des features Bag-of-Words...\")\n",
    "        \n",
    "        # Création du vectoriseur\n",
    "        self.vectorizer = CountVectorizer(\n",
    "            preprocessor=self.preprocess_text,\n",
    "            tokenizer=self.tokenize_and_stem,\n",
    "            min_df=min_df,\n",
    "            max_df=max_df,\n",
    "            max_features=max_features,\n",
    "            ngram_range=ngram_range\n",
    "        )\n",
    "        \n",
    "        # Extraction des features\n",
    "        start_time = time.time()\n",
    "        self.features = self.vectorizer.fit_transform(self.df[self.text_column])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Récupération des noms des features\n",
    "        self.feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"Extraction terminée en {end_time - start_time:.2f} secondes.\")\n",
    "        print(f\"Nombre de features: {len(self.feature_names)}\")\n",
    "        print(f\"Dimensions de la matrice: {self.features.shape}\")\n",
    "        \n",
    "        return self.features\n",
    "    \n",
    "    def visualize_feature_importance(self, top_n=20):\n",
    "        \"\"\"\n",
    "        Visualise l'importance des features pour chaque classe.\n",
    "        \n",
    "        Args:\n",
    "            top_n (int): Nombre de features importantes à afficher par classe\n",
    "            \n",
    "        Returns:\n",
    "            plotly.graph_objects.Figure: Figure des features importantes\n",
    "        \"\"\"\n",
    "        if self.features is None or self.feature_names is None:\n",
    "            print(\"Les features n'ont pas été extraites. Appelez d'abord extract_tfidf_features() ou extract_bow_features().\")\n",
    "            return None\n",
    "        \n",
    "        # Récupération des étiquettes de classe\n",
    "        y = self.df[self.class_column].values\n",
    "        \n",
    "        # Création d'une figure avec plusieurs sous-graphiques (un par classe)\n",
    "        class_ids = sorted(self.df[self.class_column].unique())\n",
    "        n_classes = len(class_ids)\n",
    "        \n",
    "        # Définir une palette de couleurs\n",
    "        colors = px.colors.qualitative.Bold\n",
    "        \n",
    "        # Création de la figure\n",
    "        fig = make_subplots(\n",
    "            rows=int(np.ceil(n_classes/2)), \n",
    "            cols=2,\n",
    "            subplot_titles=[f\"Classe {c}\" for c in class_ids]\n",
    "        )\n",
    "        \n",
    "        # Pour chaque classe\n",
    "        for i, class_id in enumerate(class_ids):\n",
    "            row = i // 2 + 1\n",
    "            col = i % 2 + 1\n",
    "            \n",
    "            # Filtre pour cette classe\n",
    "            class_mask = (y == class_id)\n",
    "            \n",
    "            # Chi2 pour les features discriminantes\n",
    "            chi2_selector = SelectKBest(chi2, k=top_n)\n",
    "            chi2_selector.fit(self.features, class_mask)\n",
    "            \n",
    "            # Récupération des scores et indices\n",
    "            scores = chi2_selector.scores_\n",
    "            indices = np.argsort(scores)[::-1][:top_n]\n",
    "            \n",
    "            # Création des données pour le graphique\n",
    "            feature_importance = []\n",
    "            for j in indices:\n",
    "                feature_importance.append({\n",
    "                    'feature': self.feature_names[j],\n",
    "                    'importance': scores[j]\n",
    "                })\n",
    "            \n",
    "            # Conversion en DataFrame\n",
    "            df_importance = pd.DataFrame(feature_importance)\n",
    "            \n",
    "            # Ajout du graphique\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    y=df_importance['feature'],\n",
    "                    x=df_importance['importance'],\n",
    "                    orientation='h',\n",
    "                    name=f\"Classe {class_id}\",\n",
    "                    marker_color=colors[i % len(colors)]\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "        \n",
    "        # Mise à jour de la mise en page\n",
    "        fig.update_layout(\n",
    "            height=300 * int(np.ceil(n_classes/2)),\n",
    "            width=1000,\n",
    "            title_text=\"Features importantes par classe\",\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "#===========================================================================================\n",
    "# 3. Extraction de features structurelles\n",
    "#===========================================================================================\n",
    "\n",
    "class GraphFeatureExtractor:\n",
    "    \"\"\"Classe pour l'extraction de features structurelles à partir du graphe.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, id_column='id'):\n",
    "        \"\"\"\n",
    "        Initialise la classe avec le DataFrame d'articles.\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame contenant les articles\n",
    "            id_column (str): Nom de la colonne contenant les identifiants des articles\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.id_column = id_column\n",
    "        \n",
    "        # Vérification de l'existence de la colonne ID\n",
    "        if id_column not in df.columns:\n",
    "            raise ValueError(f\"Colonne ID '{id_column}' non trouvée dans le DataFrame.\")\n",
    "        \n",
    "        # Attributs pour stocker les résultats\n",
    "        self.graph = None\n",
    "        self.features = None\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def build_graph(self, structural_columns, weights=None):\n",
    "        \"\"\"\n",
    "        Construit un graphe à partir des colonnes structurelles.\n",
    "        \n",
    "        Args:\n",
    "            structural_columns (dict): Dictionnaire des colonnes structurelles par type\n",
    "            weights (dict): Poids à attribuer à chaque type de relation\n",
    "            \n",
    "        Returns:\n",
    "            networkx.Graph: Graphe construit\n",
    "        \"\"\"\n",
    "        print(\"Construction du graphe à partir des colonnes structurelles...\")\n",
    "        \n",
    "        # Poids par défaut si non spécifiés\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'authors': 1.0,\n",
    "                'references': 0.5,\n",
    "                'venue': 0.3\n",
    "            }\n",
    "        \n",
    "        # Initialisation du graphe\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Ajout des nœuds (articles)\n",
    "        for i, row in enumerate(tqdm(self.df.itertuples(), total=len(self.df), desc=\"Ajout des nœuds\")):\n",
    "            article_id = getattr(row, self.id_column)\n",
    "            G.add_node(article_id, title=row.title, index=i)\n",
    "        \n",
    "        # Dictionnaire pour stocker les poids des arêtes\n",
    "        edge_weights = defaultdict(float)\n",
    "        \n",
    "        # Traitement des auteurs\n",
    "        if 'authors' in structural_columns:\n",
    "            authors_column = structural_columns['authors']\n",
    "            author_to_articles = defaultdict(set)\n",
    "            \n",
    "            # Remplissage du dictionnaire\n",
    "            for row in tqdm(self.df.itertuples(), total=len(self.df), desc=\"Traitement des auteurs\"):\n",
    "                article_id = getattr(row, self.id_column)\n",
    "                authors = getattr(row, authors_column) if hasattr(row, authors_column) else None\n",
    "                \n",
    "                if authors is None:\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(authors, list):\n",
    "                    for author in authors:\n",
    "                        author_to_articles[author].add(article_id)\n",
    "                elif isinstance(authors, str):\n",
    "                    for author in authors.split(', '):\n",
    "                        author_to_articles[author.strip()].add(article_id)\n",
    "            \n",
    "            # Ajout des poids pour les auteurs communs\n",
    "            for articles in author_to_articles.values():\n",
    "                if len(articles) > 1:\n",
    "                    articles = list(articles)\n",
    "                    for i in range(len(articles)):\n",
    "                        for j in range(i+1, len(articles)):\n",
    "                            edge = tuple(sorted([articles[i], articles[j]]))\n",
    "                            edge_weights[edge] += weights['authors']\n",
    "        \n",
    "        # Traitement des références\n",
    "        if 'references' in structural_columns:\n",
    "            references_column = structural_columns['references']\n",
    "            \n",
    "            article_to_references = {}\n",
    "            \n",
    "            # Remplissage du dictionnaire\n",
    "            for row in tqdm(self.df.itertuples(), total=len(self.df), desc=\"Traitement des références\"):\n",
    "                article_id = getattr(row, self.id_column)\n",
    "                references = getattr(row, references_column) if hasattr(row, references_column) else None\n",
    "                \n",
    "                if references is None:\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(references, list):\n",
    "                    article_to_references[article_id] = set(references)\n",
    "                elif isinstance(references, str):\n",
    "                    article_to_references[article_id] = set(ref.strip() for ref in references.split(', '))\n",
    "                else:\n",
    "                    article_to_references[article_id] = set()\n",
    "            \n",
    "            # Ensemble des IDs d'articles dans le corpus\n",
    "            article_ids = set(self.df[self.id_column])\n",
    "            \n",
    "            # Ajout des poids pour les citations directes\n",
    "            for article_id, refs in article_to_references.items():\n",
    "                for ref in refs:\n",
    "                    if ref in article_ids:\n",
    "                        edge = tuple(sorted([article_id, ref]))\n",
    "                        edge_weights[edge] += weights['references']\n",
    "            \n",
    "            # Ajout des poids pour les références partagées\n",
    "            article_ids = list(article_to_references.keys())\n",
    "            \n",
    "            for i in tqdm(range(len(article_ids)), desc=\"Traitement des références partagées\"):\n",
    "                for j in range(i+1, len(article_ids)):\n",
    "                    article1 = article_ids[i]\n",
    "                    article2 = article_ids[j]\n",
    "                    \n",
    "                    # Calcul du nombre de références partagées\n",
    "                    if article1 in article_to_references and article2 in article_to_references:\n",
    "                        shared_refs = len(article_to_references[article1].intersection(article_to_references[article2]))\n",
    "                        \n",
    "                        # Ajout du poids si des références sont partagées\n",
    "                        if shared_refs > 0:\n",
    "                            edge = tuple(sorted([article1, article2]))\n",
    "                            edge_weights[edge] += weights['references'] * min(shared_refs, 5) / 5  # Plafonnement à 5 références\n",
    "        \n",
    "        # Traitement des venues\n",
    "        if 'venue' in structural_columns:\n",
    "            venue_column = structural_columns['venue']\n",
    "            venue_to_articles = defaultdict(set)\n",
    "            \n",
    "            # Remplissage du dictionnaire\n",
    "            for row in tqdm(self.df.itertuples(), total=len(self.df), desc=\"Traitement des venues\"):\n",
    "                article_id = getattr(row, self.id_column)\n",
    "                venue = getattr(row, venue_column) if hasattr(row, venue_column) else None\n",
    "                \n",
    "                if venue is not None and pd.notna(venue) and venue:\n",
    "                    venue_to_articles[venue].add(article_id)\n",
    "            \n",
    "            # Ajout des poids pour les venues communes\n",
    "            for articles in venue_to_articles.values():\n",
    "                if len(articles) > 1:\n",
    "                    articles = list(articles)\n",
    "                    for i in range(len(articles)):\n",
    "                        for j in range(i+1, len(articles)):\n",
    "                            edge = tuple(sorted([articles[i], articles[j]]))\n",
    "                            edge_weights[edge] += weights['venue']\n",
    "        \n",
    "        # Ajout des arêtes avec leurs poids\n",
    "        for edge, weight in tqdm(edge_weights.items(), desc=\"Ajout des arêtes\"):\n",
    "            G.add_edge(*edge, weight=weight)\n",
    "        \n",
    "        print(f\"Graphe construit: {G.number_of_nodes()} nœuds, {G.number_of_edges()} arêtes\")\n",
    "        \n",
    "        # Stockage du graphe\n",
    "        self.graph = G\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def extract_graph_features(self, feature_types=None):\n",
    "        \"\"\"\n",
    "        Extrait les features structurelles à partir du graphe.\n",
    "        \n",
    "        Args:\n",
    "            feature_types (list): Liste des types de features à extraire\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Matrice des features structurelles\n",
    "        \"\"\"\n",
    "        if self.graph is None:\n",
    "            print(\"Le graphe n'a pas été construit. Appelez d'abord build_graph().\")\n",
    "            return None\n",
    "        \n",
    "        print(\"Extraction des features structurelles...\")\n",
    "        \n",
    "        # Types de features par défaut\n",
    "        if feature_types is None:\n",
    "            feature_types = ['degree', 'centrality', 'clustering', 'pagerank']\n",
    "        \n",
    "        # Construction du mapping ID -> index\n",
    "        id_to_index = {id_val: i for i, id_val in enumerate(self.df[self.id_column])}\n",
    "        \n",
    "        # Liste pour stocker les noms des features\n",
    "        feature_names = []\n",
    "        \n",
    "        # Initialisation de la matrice de features (n_samples, 0)\n",
    "        features = np.zeros((len(self.df), 0))\n",
    "        \n",
    "        # Extraction des features de degré\n",
    "        if 'degree' in feature_types:\n",
    "            print(\"Extraction des features de degré...\")\n",
    "            \n",
    "            # Degré total\n",
    "            degree = {node: val for node, val in self.graph.degree(weight='weight')}\n",
    "            degree_features = np.zeros((len(self.df), 1))\n",
    "            \n",
    "            for node, val in degree.items():\n",
    "                if node in id_to_index:\n",
    "                    degree_features[id_to_index[node], 0] = val\n",
    "            \n",
    "            # Degré entrant (pour les graphes dirigés)\n",
    "            if isinstance(self.graph, nx.DiGraph):\n",
    "                in_degree = {node: val for node, val in self.graph.in_degree(weight='weight')}\n",
    "                in_degree_features = np.zeros((len(self.df), 1))\n",
    "                \n",
    "                for node, val in in_degree.items():\n",
    "                    if node in id_to_index:\n",
    "                        in_degree_features[id_to_index[node], 0] = val\n",
    "                \n",
    "                # Degré sortant\n",
    "                out_degree = {node: val for node, val in self.graph.out_degree(weight='weight')}\n",
    "                out_degree_features = np.zeros((len(self.df), 1))\n",
    "                \n",
    "                for node, val in out_degree.items():\n",
    "                    if node in id_to_index:\n",
    "                        out_degree_features[id_to_index[node], 0] = val\n",
    "                \n",
    "                # Concaténation\n",
    "                degree_features = np.hstack([degree_features, in_degree_features, out_degree_features])\n",
    "                feature_names.extend(['degree', 'in_degree', 'out_degree'])\n",
    "            else:\n",
    "                feature_names.append('degree')\n",
    "            \n",
    "            # Ajout à la matrice de features\n",
    "            features = np.hstack([features, degree_features])\n",
    "        \n",
    "        # Extraction des features de centralité\n",
    "        if 'centrality' in feature_types:\n",
    "            print(\"Extraction des features de centralité...\")\n",
    "            \n",
    "            # Centralité de degré\n",
    "            degree_centrality = nx.degree_centrality(self.graph)\n",
    "            degree_centrality_features = np.zeros((len(self.df), 1))\n",
    "            \n",
    "            for node, val in degree_centrality.items():\n",
    "                if node in id_to_index:\n",
    "                    degree_centrality_features[id_to_index[node], 0] = val\n",
    "            \n",
    "            # Centralité d'intermédiarité (peut être coûteuse)\n",
    "            betweenness_centrality = {}\n",
    "            if self.graph.number_of_nodes() < 1000:\n",
    "                betweenness_centrality = nx.betweenness_centrality(self.graph, weight='weight')\n",
    "            else:\n",
    "                # Approximation sur un échantillon\n",
    "                betweenness_centrality = nx.betweenness_centrality(self.graph, k=100, weight='weight')\n",
    "            \n",
    "            betweenness_centrality_features = np.zeros((len(self.df), 1))\n",
    "            \n",
    "            for node, val in betweenness_centrality.items():\n",
    "                if node in id_to_index:\n",
    "                    betweenness_centrality_features[id_to_index[node], 0] = val\n",
    "            \n",
    "            # Centralité de proximité (peut être coûteuse)\n",
    "            closeness_centrality = {}\n",
    "            \n",
    "            # Calcul uniquement sur la plus grande composante connexe\n",
    "            largest_cc = max(nx.connected_components(self.graph), key=len)\n",
    "            subgraph = self.graph.subgraph(largest_cc)\n",
    "            \n",
    "            if subgraph.number_of_nodes() < 1000:\n",
    "                closeness_centrality = nx.closeness_centrality(subgraph, distance='weight')\n",
    "            \n",
    "            closeness_centrality_features = np.zeros((len(self.df), 1))\n",
    "            \n",
    "            for node, val in closeness_centrality.items():\n",
    "                if node in id_to_index:\n",
    "                    closeness_centrality_features[id_to_index[node], 0] = val\n",
    "            \n",
    "            # Concaténation\n",
    "            centrality_features = np.hstack([\n",
    "                degree_centrality_features,\n",
    "                betweenness_centrality_features,\n",
    "                closeness_centrality_features\n",
    "            ])\n",
    "            \n",
    "            feature_names.extend(['degree_centrality', 'betweenness_centrality', 'closeness_centrality'])\n",
    "            \n",
    "            # Ajout à la matrice de features\n",
    "            features = np.hstack([features, centrality_features])\n",
    "        \n",
    "        # Extraction des features de clustering\n",
    "        if 'clustering' in feature_types:\n",
    "            print(\"Extraction des features de clustering...\")\n",
    "            \n",
    "            # Coefficient de clustering\n",
    "            clustering_coef = nx.clustering(self.graph, weight='weight')\n",
    "            clustering_features = np.zeros((len(self.df), 1))\n",
    "            \n",
    "            for node, val in clustering_coef.items():\n",
    "                if node in id_to_index:\n",
    "                    clustering_features[id_to_index[node], 0] = val\n",
    "            \n",
    "            feature_names.append('clustering_coefficient')\n",
    "            \n",
    "            # Ajout à la matrice de features\n",
    "            features = np.hstack([features, clustering_features])\n",
    "        \n",
    "        # Extraction des features de PageRank\n",
    "        if 'pagerank' in feature_types:\n",
    "            print(\"Extraction des features de PageRank...\")\n",
    "            \n",
    "            # PageRank\n",
    "            pagerank = nx.pagerank(self.graph, weight='weight')\n",
    "            pagerank_features = np.zeros((len(self.df), 1))\n",
    "            \n",
    "            for node, val in pagerank.items():\n",
    "                if node in id_to_index:\n",
    "                    pagerank_features[id_to_index[node], 0] = val\n",
    "            \n",
    "            feature_names.append('pagerank')\n",
    "            \n",
    "            # Ajout à la matrice de features\n",
    "            features = np.hstack([features, pagerank_features])\n",
    "        \n",
    "        # Stockage des résultats\n",
    "        self.features = features\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "        print(f\"Extraction terminée. Dimensions de la matrice: {features.shape}\")\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def visualize_graph_features(self):\n",
    "        \"\"\"\n",
    "        Visualise la distribution des features structurelles.\n",
    "        \n",
    "        Returns:\n",
    "            plotly.graph_objects.Figure: Figure de la distribution des features\n",
    "        \"\"\"\n",
    "        if self.features is None or self.feature_names is None:\n",
    "            print(\"Les features n'ont pas été extraites. Appelez d'abord extract_graph_features().\")\n",
    "            return None\n",
    "        \n",
    "        # Création de la figure\n",
    "        fig = make_subplots(\n",
    "            rows=int(np.ceil(len(self.feature_names)/2)), \n",
    "            cols=2,\n",
    "            subplot_titles=self.feature_names\n",
    "        )\n",
    "        \n",
    "        # Pour chaque feature\n",
    "        for i, feature_name in enumerate(self.feature_names):\n",
    "            row = i // 2 + 1\n",
    "            col = i % 2 + 1\n",
    "            \n",
    "            # Extraction des valeurs\n",
    "            values = self.features[:, i]\n",
    "            \n",
    "            # Histogramme\n",
    "            fig.add_trace(\n",
    "                go.Histogram(x=values, name=feature_name),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            \n",
    "            # Mise à jour des axes\n",
    "            fig.update_xaxes(title_text=\"Valeur\", row=row, col=col)\n",
    "            fig.update_yaxes(title_text=\"Fréquence\", row=row, col=col)\n",
    "        \n",
    "        # Mise à jour de la mise en page\n",
    "        fig.update_layout(\n",
    "            height=300 * int(np.ceil(len(self.feature_names)/2)),\n",
    "            width=900,\n",
    "            title_text=\"Distribution des features structurelles\",\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "#===========================================================================================\n",
    "# 4. Combinaison des features et classification\n",
    "#===========================================================================================\n",
    "\n",
    "class DocumentClassifier:\n",
    "    \"\"\"Classe pour la classification des documents en combinant features textuelles et structurelles.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, text_features=None, graph_features=None, class_column='class'):\n",
    "        \"\"\"\n",
    "        Initialise la classe avec le DataFrame d'articles et les features.\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame contenant les articles\n",
    "            text_features (scipy.sparse.csr_matrix): Matrice des features textuelles\n",
    "            graph_features (numpy.ndarray): Matrice des features structurelles\n",
    "            class_column (str): Nom de la colonne contenant les étiquettes de classe\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.text_features = text_features\n",
    "        self.graph_features = graph_features\n",
    "        self.class_column = class_column\n",
    "        \n",
    "        # Vérification de la colonne de classe\n",
    "        if class_column not in df.columns:\n",
    "            raise ValueError(f\"Colonne de classe '{class_column}' non trouvée dans le DataFrame.\")\n",
    "        \n",
    "        # Récupération des étiquettes de classe\n",
    "        self.y = df[class_column].values\n",
    "        \n",
    "        # Attributs pour stocker les résultats\n",
    "        self.X = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def combine_features(self, standardize_graph=True):\n",
    "        \"\"\"\n",
    "        Combine les features textuelles et structurelles.\n",
    "        \n",
    "        Args:\n",
    "            standardize_graph (bool): Standardiser les features structurelles\n",
    "            \n",
    "        Returns:\n",
    "            scipy.sparse.csr_matrix: Matrice des features combinées\n",
    "        \"\"\"\n",
    "        print(\"Combinaison des features textuelles et structurelles...\")\n",
    "        \n",
    "        # Vérification des features\n",
    "        if self.text_features is None and self.graph_features is None:\n",
    "            raise ValueError(\"Aucune feature disponible. Veuillez fournir des features textuelles et/ou structurelles.\")\n",
    "        \n",
    "        # Cas où seules les features textuelles sont disponibles\n",
    "        if self.text_features is not None and self.graph_features is None:\n",
    "            print(\"Utilisation uniquement des features textuelles.\")\n",
    "            self.X = self.text_features\n",
    "            return self.X\n",
    "        \n",
    "        # Cas où seules les features structurelles sont disponibles\n",
    "        if self.text_features is None and self.graph_features is not None:\n",
    "            print(\"Utilisation uniquement des features structurelles.\")\n",
    "            \n",
    "            # Standardisation si nécessaire\n",
    "            if standardize_graph:\n",
    "                scaler = StandardScaler()\n",
    "                self.graph_features = scaler.fit_transform(self.graph_features)\n",
    "            \n",
    "            self.X = csr_matrix(self.graph_features)\n",
    "            return self.X\n",
    "        \n",
    "        # Cas où les deux types de features sont disponibles\n",
    "        if standardize_graph:\n",
    "            scaler = StandardScaler()\n",
    "            graph_features_scaled = scaler.fit_transform(self.graph_features)\n",
    "        else:\n",
    "            graph_features_scaled = self.graph_features\n",
    "        \n",
    "        # Conversion des features structurelles en matrice sparse\n",
    "        graph_features_sparse = csr_matrix(graph_features_scaled)\n",
    "        \n",
    "        # Combinaison horizontale des matrices\n",
    "        self.X = hstack([self.text_features, graph_features_sparse])\n",
    "        \n",
    "        print(f\"Features combinées. Dimensions de la matrice: {self.X.shape}\")\n",
    "        \n",
    "        return self.X\n",
    "    \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Divise les données en ensembles d'entraînement et de test.\n",
    "        \n",
    "        Args:\n",
    "            test_size (float): Proportion de l'ensemble de test\n",
    "            random_state (int): Seed pour la reproductibilité\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (X_train, X_test, y_train, y_test)\n",
    "        \"\"\"\n",
    "        if self.X is None:\n",
    "            raise ValueError(\"Les features n'ont pas été combinées. Appelez d'abord combine_features().\")\n",
    "        \n",
    "        print(f\"Division des données (test_size={test_size})...\")\n",
    "        \n",
    "        # Division des données\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state, stratify=self.y\n",
    "        )\n",
    "        \n",
    "        print(f\"Ensemble d'entraînement: {self.X_train.shape}\")\n",
    "        print(f\"Ensemble de test: {self.X_test.shape}\")\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def train_model(self, model_type='svm', **kwargs):\n",
    "        \"\"\"\n",
    "        Entraîne un modèle de classification.\n",
    "        \n",
    "        Args:\n",
    "            model_type (str): Type de modèle ('svm', 'rf', 'lr', 'nb', 'knn', 'gb', 'mlp')\n",
    "            **kwargs: Paramètres spécifiques au modèle\n",
    "            \n",
    "        Returns:\n",
    "            object: Modèle entraîné\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Les données n'ont pas été divisées. Appelez d'abord split_data().\")\n",
    "        \n",
    "        print(f\"Entraînement d'un modèle {model_type}...\")\n",
    "        \n",
    "        # Création du modèle\n",
    "        if model_type == 'svm':\n",
    "            model = SVC(probability=True, **kwargs)\n",
    "        elif model_type == 'linear_svm':\n",
    "            model = LinearSVC(**kwargs)\n",
    "        elif model_type == 'rf':\n",
    "            model = RandomForestClassifier(**kwargs)\n",
    "        elif model_type == 'lr':\n",
    "            model = LogisticRegression(**kwargs)\n",
    "        elif model_type == 'nb':\n",
    "            model = MultinomialNB(**kwargs)\n",
    "        elif model_type == 'knn':\n",
    "            model = KNeighborsClassifier(**kwargs)\n",
    "        elif model_type == 'gb':\n",
    "            model = GradientBoostingClassifier(**kwargs)\n",
    "        elif model_type == 'mlp':\n",
    "            model = MLPClassifier(**kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Type de modèle '{model_type}' non reconnu.\")\n",
    "        \n",
    "        # Entraînement du modèle\n",
    "        start_time = time.time()\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"Entraînement terminé en {end_time - start_time:.2f} secondes.\")\n",
    "        \n",
    "        # Stockage du modèle\n",
    "        self.models[model_type] = model\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def evaluate_model(self, model_type=None, model=None):\n",
    "        \"\"\"\n",
    "        Évalue un modèle sur l'ensemble de test.\n",
    "        \n",
    "        Args:\n",
    "            model_type (str): Type de modèle à évaluer\n",
    "            model (object): Modèle à évaluer (si model_type n'est pas spécifié)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Résultats de l'évaluation\n",
    "        \"\"\"\n",
    "        if self.X_test is None or self.y_test is None:\n",
    "            raise ValueError(\"Les données n'ont pas été divisées. Appelez d'abord split_data().\")\n",
    "        \n",
    "        if model is None:\n",
    "            if model_type is None or model_type not in self.models:\n",
    "                raise ValueError(f\"Type de modèle '{model_type}' non disponible. Entraînez d'abord le modèle avec train_model().\")\n",
    "            \n",
    "            model = self.models[model_type]\n",
    "        else:\n",
    "            model_type = model.__class__.__name__\n",
    "        \n",
    "        print(f\"Évaluation du modèle {model_type}...\")\n",
    "        \n",
    "        # Prédictions sur l'ensemble de test\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        \n",
    "        # Calcul des métriques\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        report = classification_report(self.y_test, y_pred, output_dict=True)\n",
    "        conf_matrix = confusion_matrix(self.y_test, y_pred)\n",
    "        \n",
    "        print(f\"Exactitude (accuracy): {accuracy:.4f}\")\n",
    "        print(\"\\nRapport de classification:\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "        \n",
    "        # Stockage des résultats\n",
    "        results = {\n",
    "            'model_type': model_type,\n",
    "            'accuracy': accuracy,\n",
    "            'report': report,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "        \n",
    "        self.results[model_type] = results\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def train_and_evaluate_multiple_models(self, models_config=None):\n",
    "        \"\"\"\n",
    "        Entraîne et évalue plusieurs modèles.\n",
    "        \n",
    "        Args:\n",
    "            models_config (list): Liste de configurations de modèles\n",
    "            \n",
    "        Returns:\n",
    "            dict: Résultats de l'évaluation pour chaque modèle\n",
    "        \"\"\"\n",
    "        if models_config is None:\n",
    "            # Configuration par défaut\n",
    "            models_config = [\n",
    "                {'type': 'svm', 'params': {'C': 1.0, 'kernel': 'linear', 'random_state': 42}},\n",
    "                {'type': 'rf', 'params': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42}},\n",
    "                {'type': 'lr', 'params': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}},\n",
    "                {'type': 'nb', 'params': {'alpha': 0.1}},\n",
    "                {'type': 'knn', 'params': {'n_neighbors': 5, 'weights': 'distance'}}\n",
    "            ]\n",
    "        \n",
    "        # Pour chaque configuration\n",
    "        for config in models_config:\n",
    "            model_type = config['type']\n",
    "            params = config['params']\n",
    "            \n",
    "            # Entraînement du modèle\n",
    "            model = self.train_model(model_type=model_type, **params)\n",
    "            \n",
    "            # Évaluation du modèle\n",
    "            self.evaluate_model(model=model)\n",
    "        \n",
    "        # Affichage comparatif\n",
    "        print(\"\\nComparaison des modèles:\")\n",
    "        for model_type, results in self.results.items():\n",
    "            print(f\"{model_type}: Accuracy = {results['accuracy']:.4f}\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def optimize_hyperparameters(self, model_type='svm', param_grid=None, cv=5, scoring='accuracy'):\n",
    "        \"\"\"\n",
    "        Optimise les hyperparamètres d'un modèle.\n",
    "        \n",
    "        Args:\n",
    "            model_type (str): Type de modèle à optimiser\n",
    "            param_grid (dict): Grille de paramètres à tester\n",
    "            cv (int): Nombre de plis pour la validation croisée\n",
    "            scoring (str): Métrique pour l'évaluation\n",
    "            \n",
    "        Returns:\n",
    "            dict: Meilleurs paramètres et résultats\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Les features n'ont pas été combinées. Appelez d'abord combine_features().\")\n",
    "        \n",
    "        print(f\"Optimisation des hyperparamètres pour le modèle {model_type}...\")\n",
    "        \n",
    "        # Grilles de paramètres par défaut\n",
    "        if param_grid is None:\n",
    "            if model_type == 'svm':\n",
    "                param_grid = {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'kernel': ['linear', 'rbf'],\n",
    "                    'gamma': ['scale', 'auto', 0.1]\n",
    "                }\n",
    "            elif model_type == 'linear_svm':\n",
    "                param_grid = {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'dual': [True, False],\n",
    "                    'max_iter': [1000, 2000]\n",
    "                }\n",
    "            elif model_type == 'rf':\n",
    "                param_grid = {\n",
    "                    'n_estimators': [50, 100],\n",
    "                    'max_depth': [10, 20, None],\n",
    "                    'min_samples_split': [2, 5, 10]\n",
    "                }\n",
    "            elif model_type == 'lr':\n",
    "                param_grid = {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'solver': ['liblinear', 'saga'],\n",
    "                    'penalty': ['l1', 'l2']\n",
    "                }\n",
    "            elif model_type == 'nb':\n",
    "                param_grid = {\n",
    "                    'alpha': [0.01, 0.1, 0.5, 1.0]\n",
    "                }\n",
    "            elif model_type == 'knn':\n",
    "                param_grid = {\n",
    "                    'n_neighbors': [3, 5, 7, 9],\n",
    "                    'weights': ['uniform', 'distance'],\n",
    "                    'p': [1, 2]  # 1 = manhattan, 2 = euclidean\n",
    "                }\n",
    "            elif model_type == 'gb':\n",
    "                param_grid = {\n",
    "                    'n_estimators': [50, 100],\n",
    "                    'learning_rate': [0.01, 0.1],\n",
    "                    'max_depth': [3, 5]\n",
    "                }\n",
    "            elif model_type == 'mlp':\n",
    "                param_grid = {\n",
    "                    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "                    'activation': ['relu', 'tanh'],\n",
    "                    'alpha': [0.0001, 0.001, 0.01]\n",
    "                }\n",
    "            else:\n",
    "                raise ValueError(f\"Type de modèle '{model_type}' non reconnu.\")\n",
    "        \n",
    "        # Création du modèle de base\n",
    "        if model_type == 'svm':\n",
    "            model = SVC(probability=True)\n",
    "        elif model_type == 'linear_svm':\n",
    "            model = LinearSVC()\n",
    "        elif model_type == 'rf':\n",
    "            model = RandomForestClassifier()\n",
    "        elif model_type == 'lr':\n",
    "            model = LogisticRegression()\n",
    "        elif model_type == 'nb':\n",
    "            model = MultinomialNB()\n",
    "        elif model_type == 'knn':\n",
    "            model = KNeighborsClassifier()\n",
    "        elif model_type == 'gb':\n",
    "            model = GradientBoostingClassifier()\n",
    "        elif model_type == 'mlp':\n",
    "            model = MLPClassifier()\n",
    "        else:\n",
    "            raise ValueError(f\"Type de modèle '{model_type}' non reconnu.\")\n",
    "        \n",
    "        # Création de la recherche sur grille\n",
    "        grid_search = GridSearchCV(\n",
    "            model,\n",
    "            param_grid,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Entraînement du modèle\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(self.X, self.y)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"Optimisation terminée en {end_time - start_time:.2f} secondes.\")\n",
    "        print(f\"Meilleurs paramètres: {grid_search.best_params_}\")\n",
    "        print(f\"Meilleur score: {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        # Entraînement du modèle avec les meilleurs paramètres\n",
    "        self.train_model(model_type=model_type, **grid_search.best_params_)\n",
    "        \n",
    "        # Stockage des résultats\n",
    "        results = {\n",
    "            'model_type': model_type,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'cv_results': grid_search.cv_results_\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_confusion_matrix(self, model_type=None, normalize=True):\n",
    "        \"\"\"\n",
    "        Visualise la matrice de confusion.\n",
    "        \n",
    "        Args:\n",
    "            model_type (str): Type de modèle à visualiser\n",
    "            normalize (bool): Normaliser la matrice de confusion\n",
    "            \n",
    "        Returns:\n",
    "            plotly.graph_objects.Figure: Figure de la matrice de confusion\n",
    "        \"\"\"\n",
    "        if model_type is None:\n",
    "            if not self.results:\n",
    "                raise ValueError(\"Aucun modèle évalué. Appelez d'abord evaluate_model().\")\n",
    "            \n",
    "            # Utiliser le premier modèle disponible\n",
    "            model_type = list(self.results.keys())[0]\n",
    "        \n",
    "        if model_type not in self.results:\n",
    "            raise ValueError(f\"Type de modèle '{model_type}' non évalué. Appelez d'abord evaluate_model().\")\n",
    "        \n",
    "        # Récupération de la matrice de confusion\n",
    "        conf_matrix = self.results[model_type]['confusion_matrix']\n",
    "        \n",
    "        # Normalisation si nécessaire\n",
    "        if normalize:\n",
    "            conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "            conf_matrix = np.round(conf_matrix, 2)\n",
    "        \n",
    "        # Classes uniques\n",
    "        class_ids = sorted(np.unique(self.y))\n",
    "        \n",
    "        # Mapping des classes\n",
    "        class_mapping = {\n",
    "            1: \"Artificial Intelligence\",\n",
    "            2: \"Data Science\",\n",
    "            3: \"Interface\",\n",
    "            4: \"Computer Vision\",\n",
    "            5: \"Network\",\n",
    "            6: \"Theoretical CS\",\n",
    "            7: \"Specific Applications\",\n",
    "            8: \"Other\"\n",
    "        }\n",
    "        \n",
    "        class_names = [class_mapping.get(c, f\"Class {c}\") for c in class_ids]\n",
    "        \n",
    "        # Création de la figure\n",
    "        fig = px.imshow(\n",
    "            conf_matrix,\n",
    "            x=class_names,\n",
    "            y=class_names,\n",
    "            color_continuous_scale='viridis',\n",
    "            labels=dict(x=\"Prédiction\", y=\"Vraie classe\", color=\"Proportion\" if normalize else \"Nombre\"),\n",
    "            title=f\"Matrice de confusion - {model_type}\"\n",
    "        )\n",
    "        \n",
    "        # Ajout des annotations\n",
    "        annotations = []\n",
    "        for i, row in enumerate(conf_matrix):\n",
    "            for j, value in enumerate(row):\n",
    "                annotations.append(\n",
    "                    dict(\n",
    "                        x=j,\n",
    "                        y=i,\n",
    "                        text=str(value),\n",
    "                        showarrow=False,\n",
    "                        font=dict(color='white' if value > 0.5 else 'black')\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        fig.update_layout(annotations=annotations)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def visualize_feature_importance(self, model_type='rf', top_n=20):\n",
    "        \"\"\"\n",
    "        Visualise l'importance des features pour un modèle.\n",
    "        \n",
    "        Args:\n",
    "            model_type (str): Type de modèle ('rf', 'gb' ou 'linear_svm')\n",
    "            top_n (int): Nombre de features importantes à afficher\n",
    "            \n",
    "        Returns:\n",
    "            plotly.graph_objects.Figure: Figure de l'importance des features\n",
    "        \"\"\"\n",
    "        if model_type not in self.models:\n",
    "            raise ValueError(f\"Type de modèle '{model_type}' non disponible. Entraînez d'abord le modèle avec train_model().\")\n",
    "        \n",
    "        model = self.models[model_type]\n",
    "        \n",
    "        # Vérification du type de modèle\n",
    "        if not hasattr(model, 'feature_importances_') and not hasattr(model, 'coef_'):\n",
    "            print(f\"Le modèle {model_type} ne fournit pas d'importance des features.\")\n",
    "            return None\n",
    "        \n",
    "        # Extraction de l'importance des features\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Pour RandomForest, GradientBoosting, etc.\n",
    "            feature_importance = model.feature_importances_\n",
    "        else:\n",
    "            # Pour les modèles linéaires (LinearSVC, LogisticRegression, etc.)\n",
    "            feature_importance = np.abs(model.coef_).mean(axis=0)\n",
    "        \n",
    "        # Récupération des noms des features\n",
    "        feature_names = []\n",
    "        \n",
    "        if hasattr(self, 'text_features') and self.text_features is not None:\n",
    "            # Features textuelles\n",
    "            if hasattr(self, 'text_feature_extractor') and hasattr(self.text_feature_extractor, 'feature_names'):\n",
    "                feature_names.extend(self.text_feature_extractor.feature_names)\n",
    "            else:\n",
    "                feature_names.extend([f'text_{i}' for i in range(self.text_features.shape[1])])\n",
    "        \n",
    "        if hasattr(self, 'graph_features') and self.graph_features is not None:\n",
    "            # Features structurelles\n",
    "            if hasattr(self, 'graph_feature_extractor') and hasattr(self.graph_feature_extractor, 'feature_names'):\n",
    "                feature_names.extend(self.graph_feature_extractor.feature_names)\n",
    "            else:\n",
    "                feature_names.extend([f'graph_{i}' for i in range(self.graph_features.shape[1])])\n",
    "        \n",
    "        # S'assurer que le nombre de noms correspond au nombre de features\n",
    "        if len(feature_names) != len(feature_importance):\n",
    "            print(f\"Attention: Le nombre de noms de features ({len(feature_names)}) ne correspond pas au nombre de features ({len(feature_importance)}).\")\n",
    "            feature_names = [f'feature_{i}' for i in range(len(feature_importance))]\n",
    "        \n",
    "        # Création d'un DataFrame pour la visualisation\n",
    "        df_importance = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        })\n",
    "        \n",
    "        # Tri par importance décroissante\n",
    "        df_importance = df_importance.sort_values('importance', ascending=False).head(top_n)\n",
    "        \n",
    "        # Création de la figure\n",
    "        fig = px.bar(\n",
    "            df_importance,\n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            orientation='h',\n",
    "            labels={'importance': 'Importance', 'feature': 'Feature'},\n",
    "            title=f\"Importance des features - {model_type}\"\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=600, width=800)\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# Création de la colonne 'class' à partir de la colonne 'venue'\n",
    "def assign_class_from_venue(venue_name):\n",
    "    \"\"\"Assigne une classe (1-8) en fonction du nom de la conférence/journal\"\"\"\n",
    "    venue_lower = str(venue_name).lower() if pd.notna(venue_name) else \"\"\n",
    "    \n",
    "    # Classification selon les critères donnés dans l'énoncé\n",
    "    if any(term in venue_lower for term in ['machine learning', 'artificial intelligence', 'neural', \n",
    "                                           'autonomous', 'agent', 'nlp', 'natural language']):\n",
    "        return 1  # Artificial Intelligence\n",
    "    elif any(term in venue_lower for term in ['data', 'information system', 'database', 'mining', \n",
    "                                             'cleaning', 'business intelligence']):\n",
    "        return 2  # Data Science\n",
    "    elif any(term in venue_lower for term in ['visualization', 'interface', 'interaction', 'hci']):\n",
    "        return 3  # Interface\n",
    "    elif any(term in venue_lower for term in ['vision', 'image', '2d', '3d', 'virtual reality']):\n",
    "        return 4  # Computer Vision\n",
    "    elif any(term in venue_lower for term in ['network', 'system', 'security', 'mobile', 'iot', 'web']):\n",
    "        return 5  # Network\n",
    "    elif any(term in venue_lower for term in ['theory', 'theorem', 'proof', 'bound', \n",
    "                                             'calculability', 'compilation', 'game theory']):\n",
    "        return 6  # Theoretical CS\n",
    "    elif any(term in venue_lower for term in ['humanities', 'biology', 'medicine', 'chemistry',\n",
    "                                             'physics', 'social']):\n",
    "        return 7  # Specific Applications\n",
    "    else:\n",
    "        return 8  # Other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées avec succès. Shape: (79007, 13)\n"
     ]
    }
   ],
   "source": [
    "# 1. Chargement des données\n",
    "input_file = \"articles_with_clusters.pkl\"\n",
    "df = load_processed_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1     2468\n",
      "2     2862\n",
      "3      643\n",
      "4     2529\n",
      "5     9237\n",
      "6     1306\n",
      "7     1016\n",
      "8    58946\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Application de la fonction pour créer la colonne 'class'\n",
    "df['class'] = df['venue'].apply(assign_class_from_venue)\n",
    "\n",
    "# Vérification de la répartition des classes\n",
    "print(df['class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Préparation des données\n",
    "df = prepare_text_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'articles classifiés: 79007\n",
      "Classe 1 (Artificial Intelligence): 2468 articles (3.1%)\n",
      "Classe 2 (Data Science): 2862 articles (3.6%)\n",
      "Classe 3 (Interface): 643 articles (0.8%)\n",
      "Classe 4 (Computer Vision): 2529 articles (3.2%)\n",
      "Classe 5 (Network): 9237 articles (11.7%)\n",
      "Classe 6 (Theoretical CS): 1306 articles (1.7%)\n",
      "Classe 7 (Specific Applications): 1016 articles (1.3%)\n",
      "Classe 8 (Other): 58946 articles (74.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Artificial Intelligence<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Artificial Intelligence",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Artificial Intelligence",
         "offsetgroup": "Artificial Intelligence",
         "orientation": "v",
         "showlegend": true,
         "text": [
          2468
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          1
         ],
         "xaxis": "x",
         "y": [
          2468
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Data Science<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Data Science",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Data Science",
         "offsetgroup": "Data Science",
         "orientation": "v",
         "showlegend": true,
         "text": [
          2862
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          2
         ],
         "xaxis": "x",
         "y": [
          2862
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Interface<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Interface",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Interface",
         "offsetgroup": "Interface",
         "orientation": "v",
         "showlegend": true,
         "text": [
          643
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          3
         ],
         "xaxis": "x",
         "y": [
          643
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Computer Vision<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Computer Vision",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Computer Vision",
         "offsetgroup": "Computer Vision",
         "orientation": "v",
         "showlegend": true,
         "text": [
          2529
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          4
         ],
         "xaxis": "x",
         "y": [
          2529
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Network<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Network",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Network",
         "offsetgroup": "Network",
         "orientation": "v",
         "showlegend": true,
         "text": [
          9237
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          5
         ],
         "xaxis": "x",
         "y": [
          9237
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Theoretical CS<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Theoretical CS",
         "marker": {
          "color": "#19d3f3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Theoretical CS",
         "offsetgroup": "Theoretical CS",
         "orientation": "v",
         "showlegend": true,
         "text": [
          1306
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          6
         ],
         "xaxis": "x",
         "y": [
          1306
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Specific Applications<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Specific Applications",
         "marker": {
          "color": "#FF6692",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Specific Applications",
         "offsetgroup": "Specific Applications",
         "orientation": "v",
         "showlegend": true,
         "text": [
          1016
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          7
         ],
         "xaxis": "x",
         "y": [
          1016
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Domaine=Other<br>Classe=%{x}<br>Nombre d'articles=%{text}<extra></extra>",
         "legendgroup": "Other",
         "marker": {
          "color": "#B6E880",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Other",
         "offsetgroup": "Other",
         "orientation": "v",
         "showlegend": true,
         "text": [
          58946
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          8
         ],
         "xaxis": "x",
         "y": [
          58946
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Domaine"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution des classes dans le corpus"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Classe"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Nombre d'articles"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Exploration de la distribution des classes\n",
    "fig = explore_class_distribution(df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction des features TF-IDF...\n",
      "Extraction terminée en 162.37 secondes.\n",
      "Nombre de features: 160862\n",
      "Dimensions de la matrice: (79007, 160862)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "rgb(127, 60, 141)"
         },
         "name": "Classe 1",
         "orientation": "h",
         "type": "bar",
         "x": [
          143.65216149562244,
          111.85833833680275,
          104.10758460251932,
          102.10101130206783,
          78.08598438754134,
          67.60916055232643,
          64.80228456871325,
          62.79111889073483,
          55.3364088213499,
          49.93028228454657,
          49.575308032486554,
          48.75225265805882,
          48.32596789158684,
          44.36158418032346,
          40.476331398728895,
          40.38254919311703,
          38.44317909578285,
          37.75717464451351,
          36.05175898576025,
          35.96277551068925
         ],
         "xaxis": "x",
         "y": [
          "agent",
          "learn",
          "multiag",
          "reinforc learn",
          "reinforc",
          "ai",
          "plan tempor",
          "plan recognit",
          "dcop",
          "bandit",
          "autonom agent",
          "multi agent",
          "bdi",
          "classic plan",
          "multiag system",
          "briberi",
          "bdi agent",
          "plan",
          "atl",
          "regret"
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "rgb(17, 165, 121)"
         },
         "name": "Classe 2",
         "orientation": "h",
         "type": "bar",
         "x": [
          250.70193005696734,
          116.88476297631198,
          104.90097519875354,
          77.39808673909049,
          68.975072463603,
          68.42411848323678,
          52.334331543764314,
          52.31775835114853,
          51.6891702236463,
          50.636691503042734,
          47.79437227857751,
          46.20813264091347,
          44.78880799303974,
          44.544751054730035,
          44.130610859791126,
          41.84589054879196,
          39.95744786345455,
          39.439979773315486,
          33.91027623726274,
          33.69904114982617
         ],
         "xaxis": "x2",
         "y": [
          "queri",
          "sql",
          "databas",
          "join",
          "similar join",
          "top k",
          "concurr control",
          "oltp",
          "databas system",
          "record linkag",
          "entiti resolut",
          "recommend",
          "skylin",
          "dado",
          "conjunct queri",
          "mine",
          "graph",
          "queri process",
          "relat dataset",
          "distanc oracl"
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "rgb(57, 105, 172)"
         },
         "name": "Classe 3",
         "orientation": "h",
         "type": "bar",
         "x": [
          846.7075616667169,
          613.0907767033794,
          517.3443883324084,
          507.9329719162338,
          402.41764175926096,
          200.61809061495308,
          194.901517667995,
          166.44963988121668,
          164.60541199549772,
          142.06056743556755,
          139.68463821853072,
          134.6555130108004,
          132.87178307392335,
          131.8870511404331,
          124.01449594300851,
          109.16736328377742,
          102.37963758537039,
          96.57989589230428,
          95.28638560736731,
          94.75699818454974
         ],
         "xaxis": "x3",
         "y": [
          "robot",
          "hri",
          "social robot",
          "human robot",
          "robot interact",
          "human",
          "child robot",
          "interact",
          "interact hri",
          "toward robot",
          "telepres",
          "hug",
          "robot behavior",
          "telepres robot",
          "interact robot",
          "intellig user",
          "human collabor",
          "social assist",
          "percept robot",
          "robot tutor"
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "rgb(242, 183, 1)"
         },
         "name": "Classe 4",
         "orientation": "h",
         "type": "bar",
         "x": [
          590.3086782550936,
          260.3756666425533,
          190.53460986337072,
          189.16456931755636,
          172.84104843672264,
          133.7611242630918,
          124.90207592641953,
          119.01999358095674,
          111.09393872175893,
          104.56154702947406,
          101.55370776373883,
          88.93848397692037,
          87.47412411459432,
          86.37911985899576,
          85.6554098873067,
          82.85539858546014,
          81.91016060704524,
          81.35680305549965,
          77.78905620360185,
          75.5083625128328
         ],
         "xaxis": "x4",
         "y": [
          "imag",
          "video",
          "convolut",
          "cnn",
          "segment",
          "scene",
          "camera",
          "convolut neural",
          "face",
          "deep",
          "vr",
          "pose",
          "rgb",
          "stereo",
          "salienc",
          "depth",
          "fcn",
          "facial",
          "motion",
          "reconstruct"
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "rgb(231, 63, 116)"
         },
         "name": "Classe 5",
         "orientation": "h",
         "type": "bar",
         "x": [
          194.85692940725008,
          62.087037461517966,
          50.02385306274844,
          43.2998133898414,
          38.69650032924841,
          38.56286955144212,
          37.794766104843575,
          36.2794130893515,
          34.10589653621591,
          33.3826343389677,
          32.29915587479387,
          30.359121292792377,
          30.042531665265976,
          28.241287540508747,
          26.030534389188052,
          25.934052465023683,
          24.903860831550897,
          24.345093911180086,
          23.535235318122012,
          23.053392228896044
         ],
         "xaxis": "x5",
         "y": [
          "minitrack",
          "attack",
          "xf",
          "network",
          "secur",
          "competit contribut",
          "introduct",
          "wireless",
          "malwar",
          "cellular automata",
          "privaci",
          "cyber",
          "fuzzi",
          "sensor network",
          "traffic",
          "mobil",
          "social media",
          "system",
          "rout",
          "control"
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "rgb(128, 186, 90)"
         },
         "name": "Classe 6",
         "orientation": "h",
         "type": "bar",
         "x": [
          354.27913625466795,
          218.86226473655387,
          164.56585327166604,
          132.97065794275312,
          118.99971239429468,
          97.08802202210742,
          91.59621855321089,
          84.51860182368782,
          81.32790763395312,
          79.19066425538536,
          73.523354494011,
          71.50821272759893,
          71.15400495007188,
          69.79490883501862,
          68.41742019986023,
          67.57711621782565,
          67.05396985437739,
          63.5274655905096,
          63.36701735302167,
          62.95378857223673
         ],
         "xaxis": "x6",
         "y": [
          "code",
          "channel",
          "decod",
          "ldpc",
          "ldpc code",
          "code construct",
          "capac region",
          "broadcast channel",
          "bound",
          "blocklength",
          "capac",
          "gdof",
          "erasur channel",
          "write memori",
          "singl letter",
          "erasur",
          "interfer channel",
          "achiev rate",
          "protograph",
          "side inform"
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": "rgb(230, 131, 16)"
         },
         "name": "Classe 7",
         "orientation": "h",
         "type": "bar",
         "x": [
          229.33144559607302,
          206.386494345807,
          173.52828619008432,
          152.10721105092966,
          149.33310613265076,
          134.75367426071213,
          124.70864526113542,
          122.52397284353478,
          109.45904152855181,
          107.08597432859658,
          106.63458600532522,
          106.05674681941497,
          104.86338695863937,
          95.75735937924668,
          89.11133001896421,
          88.21222715492192,
          85.9877067892826,
          82.46680404670994,
          80.16479797996045,
          80.16479797996045
         ],
         "xaxis": "x7",
         "y": [
          "background object",
          "quantum",
          "protein",
          "n program",
          "n method",
          "n conclus",
          "excit state",
          "finit volum",
          "r n",
          "method r",
          "energi surfac",
          "fluid",
          "conclus r",
          "transfer reaction",
          "immers boundari",
          "aromat",
          "r",
          "charg transfer",
          "wiley period",
          "period inc"
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": "rgb(0, 134, 149)"
         },
         "name": "Classe 8",
         "orientation": "h",
         "type": "bar",
         "x": [
          73.99348689022646,
          25.898691814687634,
          24.217056056512053,
          21.035454497733948,
          20.65053762021824,
          19.459923223730364,
          19.274256302609473,
          17.449140558051795,
          16.73175653136733,
          16.673865252032698,
          16.072967026408676,
          15.563460547311989,
          15.00145300315982,
          14.763412676631386,
          13.971186128509833,
          13.956518637092092,
          13.933750317346195,
          13.72236730621813,
          13.647206610170763,
          13.167943939749826
         ],
         "xaxis": "x8",
         "y": [
          "minitrack",
          "speech",
          "social",
          "dataset",
          "multiag",
          "xf",
          "agent",
          "multiag system",
          "network",
          "student",
          "recommend",
          "user",
          "competit contribut",
          "video",
          "von",
          "und",
          "social media",
          "human robot",
          "imag",
          "vr"
         ],
         "yaxis": "y8"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 1",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 2",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 3",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.71875,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 4",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.71875,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 5",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 6",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.4375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 7",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.15625,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Classe 8",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.15625,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1200,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Features importantes par classe"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.55,
          1
         ]
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.84375,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.84375,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.5625,
          0.71875
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.5625,
          0.71875
         ]
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0.28125,
          0.4375
         ]
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0.28125,
          0.4375
         ]
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          0.15625
         ]
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          0.15625
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Extraction des features textuelles\n",
    "text_extractor = TextFeatureExtractor(df, 'combined_text', 'class')\n",
    "text_features = text_extractor.extract_tfidf_features(min_df=5, max_df=0.95, ngram_range=(1, 2))\n",
    "\n",
    "# Visualisation de l'importance des features par classe\n",
    "fig_text_importance = text_extractor.visualize_feature_importance(top_n=20)\n",
    "fig_text_importance.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction du graphe à partir des colonnes structurelles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ajout des nœuds: 100%|██████████| 79007/79007 [00:00<00:00, 176566.82it/s]\n",
      "Traitement des auteurs: 100%|██████████| 79007/79007 [00:01<00:00, 61484.02it/s] \n",
      "Traitement des références: 100%|██████████| 79007/79007 [00:00<00:00, 176717.10it/s]\n",
      "Traitement des références partagées: 100%|██████████| 79007/79007 [27:16<00:00, 48.28it/s]  \n",
      "Traitement des venues: 100%|██████████| 79007/79007 [00:00<00:00, 286562.20it/s]\n",
      "Ajout des arêtes: 100%|██████████| 14877034/14877034 [00:33<00:00, 441508.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphe construit: 79007 nœuds, 14877034 arêtes\n",
      "Extraction des features structurelles...\n",
      "Extraction des features de degré...\n",
      "Extraction des features de centralité...\n",
      "Extraction des features de clustering...\n"
     ]
    }
   ],
   "source": [
    "# 5. Extraction des features structurelles\n",
    "# Identification des colonnes structurelles\n",
    "structural_columns = {\n",
    "    'authors': 'authors',\n",
    "    'references': 'references',\n",
    "    'venue': 'venue'\n",
    "}\n",
    "\n",
    "graph_extractor = GraphFeatureExtractor(df)\n",
    "graph = graph_extractor.build_graph(structural_columns)\n",
    "graph_features = graph_extractor.extract_graph_features()\n",
    "\n",
    "# Visualisation des features structurelles\n",
    "fig_graph_features = graph_extractor.visualize_graph_features()\n",
    "fig_graph_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Combinaison des features et classification\n",
    "classifier = DocumentClassifier(df, text_features, graph_features, 'class')\n",
    "X_combined = classifier.combine_features(standardize_graph=True)\n",
    "\n",
    "# Division des données\n",
    "classifier.split_data(test_size=0.2)\n",
    "\n",
    "# Entraînement et évaluation de plusieurs modèles\n",
    "models_config = [\n",
    "    {'type': 'svm', 'params': {'C': 1.0, 'kernel': 'linear', 'random_state': 42}},\n",
    "    {'type': 'rf', 'params': {'n_estimators': 100, 'max_depth': 10, 'random_state': 42}},\n",
    "    {'type': 'lr', 'params': {'C': 1.0, 'max_iter': 1000, 'random_state': 42}}\n",
    "]\n",
    "\n",
    "results = classifier.train_and_evaluate_multiple_models(models_config)\n",
    "\n",
    "# Visualisation de la matrice de confusion pour le meilleur modèle\n",
    "best_model = max(results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "fig_confusion = classifier.visualize_confusion_matrix(model_type=best_model)\n",
    "fig_confusion.show()\n",
    "\n",
    "# Optimisation des hyperparamètres du meilleur modèle\n",
    "opt_results = classifier.optimize_hyperparameters(model_type=best_model)\n",
    "\n",
    "# Visualisation de l'importance des features\n",
    "if best_model in ['rf', 'gb', 'linear_svm', 'lr']:\n",
    "    fig_importance = classifier.visualize_feature_importance(model_type=best_model)\n",
    "    fig_importance.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
